{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\bruno\\onedrive\\escritorio\\proyecto\\.venv\\lib\\site-packages (1.6.2)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bruno\\onedrive\\escritorio\\proyecto\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bruno\\onedrive\\escritorio\\proyecto\\.venv\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\bruno\\onedrive\\escritorio\\proyecto\\.venv\\lib\\site-packages (from xgboost) (1.21.6)\n",
      "Requirement already satisfied: scipy in c:\\users\\bruno\\onedrive\\escritorio\\proyecto\\.venv\\lib\\site-packages (from xgboost) (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "import mne_bids\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def salida_predicha(hypno):\n",
    "    hip = []\n",
    "    for k, duracion in enumerate(hypno['duration']):\n",
    "       # n_veces = int(duracion / 30)\n",
    "        \"\"\"\n",
    "        if n_veces == 0 :\n",
    "            estado = hypno['trial_type'][k]\n",
    "            hip.extend([estado] * 1)\n",
    "        else :\n",
    "        \"\"\"\n",
    "        if duracion == 0 or 0.0 :\n",
    "            n_veces = 1\n",
    "            estado = hypno['trial_type'][k]\n",
    "            hip.extend([estado] * n_veces)\n",
    "        else :\n",
    "            n_veces = int(duracion / 30)\n",
    "            estado = hypno['trial_type'][k]\n",
    "            hip.extend([estado] * n_veces)\n",
    "        \n",
    "    return hip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directorio c los dataset que voy a probar\n",
    "dic_dublin =r'H:\\Mi unidad\\FormatoBIDS\\DatasetCollegeDublin'\n",
    "dic_SC = r'H:\\Mi unidad\\FormatoBIDS\\DataseSleep-Casset'# el sujeto 003 en sc no carga el edf\n",
    "dic_DODH =  r'H:\\Mi unidad\\FormatoBIDS\\DatasetDODH'\n",
    "dic_SHHS1 = r'H:\\Mi unidad\\FormatoBIDS\\DatasetSHHS1'\n",
    "dic_agus = r'H:\\.shortcut-targets-by-id\\1oz7_KTs_0LBRN7CMTRkLDKYI--PGbP_t\\CNTR_VMA_NOCHE-BIDS_copy'  # señal\n",
    "path_agus = r'H:\\.shortcut-targets-by-id\\1epHQ10lpZXvKpjB3tVz3XnAwTgWm38El\\SUENIO'  # polisomnografia\n",
    "# Mapas para las etiquetas de sueño\n",
    "mapaSC = {'NREM1': 1, 'NREM2': 2, 'NREM3': 3, 'NREM4': 3, 'REM': 4, 'WAKE': 0, 'NO_DETECTADO': 0, 'Movement time': 0}\n",
    "mapaSHHS1 = {'NREM1': 1, 'NREM2': 2, 'NREM3': 3, 'NREM4': 3, 'REM': 4, 'WAKE': 0, 'NO_DETECTADO': 0, 'ARTEFACTO': 0}\n",
    "mapaDODH = {'NREM1': 1, 'NREM2': 2, 'NREM3': 3, 'NREM4': 3, 'REM': 4, 'WAKE': 0, 'NO_IDENTIFICADO': 0}\n",
    "\n",
    "# Directorios de los datasets\n",
    "dic_SC = r'H:\\Mi unidad\\FormatoBIDS\\DataseSleep-Casset'\n",
    "dic_DODH = r'H:\\Mi unidad\\FormatoBIDS\\DatasetDODH'\n",
    "dic_SHHS1 = r'H:\\Mi unidad\\FormatoBIDS\\DatasetSHHS1'\n",
    "\n",
    "# Metadata\n",
    "metadataSC = {'channels' : { 'eog' : ['EOG horizontal' ], 'eeg': {'central':[],'frontal' : ['EEG Fpz-Cz'], 'parietal' : ['EEG Pz-Oz'],'occipital': []}, 'emg':['EMG submental'] }}\n",
    "metadataDODH = {'channels' : { 'eog' : ['EOG1', 'EOG2' ], 'eeg': {'central':['C3_M2'],'frontal' : ['F3_M2', 'F4_M1', 'FP1_M2', 'FP2_M1'], 'parietal' : [],'occipital': ['F3_O1']}, 'emg':['EMG'] }}\n",
    "metadataSHHS1  = {'channels' : { 'eog' : ['EOG(L)', 'EOG(R)' ], 'eeg': {'central':['EEG', 'EEG(sec)'],'frontal' : [], 'parietal' : [], 'occipital': []}, 'emg':['EMG'] }}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direct_clasif_doodh = r'C:\\Users\\Bruno\\OneDrive\\Escritorio\\Proyecto\\DODHGSSC_YASA'\n",
    "data_classif = pd.read_csv(os.path.join(direct_clasif_doodh,'salida_gssc_'+ 'sub-001'+'.tsv'),  sep='\\t')\n",
    "X_value = data_classif.iloc[:,:5].values\n",
    "y_predic = data_classif.iloc[:,5].values\n",
    "\n",
    "path_annot = os.path.join(dic_SC, 'sub-001', 'ses-001', 'eeg', 'sub-001' + '_ses-001_task-sleep_events.tsv')\n",
    "anotaciones_real = pd.read_csv(path_annot, sep='\\t')\n",
    "hipno = salida_predicha(anotaciones_real)\n",
    "y_real = [int(mapaSC.get(data)) for data in hipno]\n",
    "min_length = min(len(y_real), len(y_predic))\n",
    "y_real , y_predic = y_real[:min_length], y_predic[:min_length]\n",
    "[1 if real != prediccion else 0 for real, prediccion in zip(y_real, y_predic)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  3,  5],\n",
       "       [ 1,  2, 33,  4,  7]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1 = np.array([[1, 2, 3,3,5]])\n",
    "array2 = np.array([[1, 2, 33,4,7]])\n",
    "\n",
    "X_entrada = np.zeros_like(np.arange(5))\n",
    "\n",
    "X_entrada = np.vstack((X_entrada,array1))\n",
    "X_entrada = np.vstack((X_entrada,array2))\n",
    "X_entrada = np.delete(X_entrada, 0, axis=0)\n",
    "X_entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  3],\n",
       "       [ 1,  4,  5,  5],\n",
       "       [ 1,  2, 33,  4],\n",
       "       [31,  1, 44,  2]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Usar vstack para concatenarlos verticalmente\n",
    "concatenated_array = np.vstack((array1, array2))\n",
    "concatenated_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-001\n",
      "2649 (2650, 5)\n",
      "sub-002\n",
      "5478 (5478, 5)\n",
      "sub-003\n",
      "8279 (8279, 5)\n",
      "sub-004\n",
      "11128 (11128, 5)\n",
      "sub-005\n",
      "13931 (13931, 5)\n",
      "sub-006\n",
      "16686 (16686, 5)\n",
      "sub-007\n",
      "19505 (19505, 5)\n",
      "sub-008\n",
      "22236 (22236, 5)\n",
      "sub-009\n",
      "24805 (24805, 5)\n",
      "sub-010\n",
      "27596 (27596, 5)\n",
      "sub-011\n",
      "30317 (30317, 5)\n",
      "sub-012\n",
      "33122 (33122, 5)\n",
      "sub-013\n",
      "35891 (35891, 5)\n",
      "sub-014\n",
      "38720 (38720, 5)\n",
      "sub-015\n",
      "41529 (41529, 5)\n",
      "sub-016\n",
      "44298 (44298, 5)\n",
      "sub-017\n",
      "47093 (47093, 5)\n",
      "sub-018\n",
      "49726 (49726, 5)\n",
      "sub-019\n",
      "52457 (52457, 5)\n",
      "sub-020\n",
      "55314 (55314, 5)\n",
      "sub-001\n",
      "56281 (56281, 5)\n",
      "sub-002\n",
      "57235 (57235, 5)\n",
      "sub-003\n",
      "58220 (58220, 5)\n",
      "sub-004\n",
      "58839 (58839, 5)\n",
      "sub-005\n",
      "59785 (59785, 5)\n",
      "sub-006\n",
      "60773 (60773, 5)\n",
      "sub-007\n",
      "61771 (61771, 5)\n",
      "sub-008\n",
      "62739 (62739, 5)\n",
      "sub-009\n",
      "63733 (63733, 5)\n",
      "sub-010\n",
      "64795 (64795, 5)\n",
      "sub-011\n",
      "65805 (65805, 5)\n",
      "sub-012\n",
      "66850 (66850, 5)\n",
      "sub-013\n",
      "68041 (68041, 5)\n",
      "sub-014\n",
      "68972 (68972, 5)\n",
      "sub-015\n",
      "69900 (69900, 5)\n",
      "sub-016\n",
      "70856 (70856, 5)\n",
      "sub-017\n",
      "71845 (71845, 5)\n",
      "sub-018\n",
      "72852 (72852, 5)\n",
      "sub-019\n",
      "73973 (73973, 5)\n",
      "sub-020\n",
      "74947 (74947, 5)\n"
     ]
    }
   ],
   "source": [
    "X_entrada = np.zeros_like(np.arange(5))\n",
    "Y_salida = []\n",
    "for directorio, metadata, mapa, dataset ,dic_predic in zip(\n",
    "        [dic_SC, dic_DODH],\n",
    "        [metadataSC, metadataDODH],\n",
    "        [mapaSC, mapaDODH],\n",
    "        ['SleepCasset', 'DODH'],\n",
    "        [r'C:\\Users\\Bruno\\OneDrive\\Escritorio\\Proyecto\\ScGSSC_YASA',r'C:\\Users\\Bruno\\OneDrive\\Escritorio\\Proyecto\\DODHGSSC_YASA']\n",
    "        ) :\n",
    "    \n",
    "    sujetos = mne_bids.get_entity_vals(directorio, entity_key='subject', with_key=True)\n",
    "\n",
    "    for sujeto in sujetos[0:20]: \n",
    "        print(sujeto)\n",
    "\n",
    "        \n",
    "        path_annot = os.path.join(directorio, sujeto, 'ses-001', 'eeg', sujeto + '_ses-001_task-sleep_events.tsv')\n",
    "        anotaciones_real = pd.read_csv(path_annot, sep='\\t')\n",
    "        hipno = salida_predicha(anotaciones_real)\n",
    "        y_real = [int(mapa.get(data)) for data in hipno]\n",
    "\n",
    "\n",
    "        data_classif = pd.read_csv(os.path.join(dic_predic,'salida_gssc_'+ sujeto+'.tsv'),  sep='\\t')\n",
    "\n",
    "        X_value = data_classif.iloc[:,:5].values\n",
    "        y_predic = data_classif.iloc[:,5].values\n",
    "\n",
    "        min_length = min(len(y_real), len(y_predic))\n",
    "        y_real , y_predic = y_real[:min_length], y_predic[:min_length]\n",
    "        y_value = [ 1 if real != prediccion else 0 for real, prediccion in zip(y_real, y_predic)]\n",
    "        Y_salida.extend(y_value)\n",
    "        \n",
    "        X_entrada = np.vstack((X_entrada,X_value))\n",
    "        print(len(Y_salida), X_entrada.shape)\n",
    "        if np.all(X_entrada[0] == 0):\n",
    "            # Si es así, eliminamos la primera fila\n",
    "            X_entrada = np.delete(X_entrada, 0, axis=0)\n",
    "        \n",
    "for sujeto in mne_bids.get_entity_vals(path_agus, entity_key = 'subject', with_key=True)[15:] :\n",
    "    mapeo_etiquetas = {0: 0, 1: 1, 2: 2, 3: 3 ,5 :4, 4:4, 6: 0, 7:0}\n",
    "\n",
    "    ruta_salida_deseada = os.path.join(path_agus,sujeto,'ses-day1','sleep_staging',sujeto + '_ses-day1_task-sleep_sleepStages.mat')\n",
    "    if  os.path.exists(ruta_salida_deseada) :\n",
    "        y_real__ = scipy.io.loadmat(ruta_salida_deseada)['stageData'][0][0][6][1:] # salida deseada, la del experto\n",
    "        y_real = np.array([mapeo_etiquetas[etiqueta] for etiqueta in y_real__.flatten()]).reshape(y_real__.shape) \n",
    "\n",
    "        data_classif = pd.read_csv(os.path.join(r'C:\\Users\\Bruno\\OneDrive\\Escritorio\\Proyecto\\AgusGSSC_YASA','salida_gssc_' + sujeto +'.tsv'), sep = '\\t')\n",
    "\n",
    "        X_value = data_classif.iloc[:,:5].values\n",
    "        y_predic = data_classif.iloc[:,5].values\n",
    "\n",
    "        min_length = min(len(y_real), len(y_predic))\n",
    "        y_real , y_predic = y_real[:min_length], y_predic[:min_length]\n",
    "        y_value = [ 1 if real != prediccion else 0 for real, prediccion in zip(y_real, y_predic)]\n",
    "        Y_salida.extend(y_value)\n",
    "        X_entrada = np.vstack((X_entrada,X_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Suponiendo que X_entrada es tu conjunto de características y Y_salida son las etiquetas de clase (0 y 1)\n",
    "# 1. Encuentra las posiciones de las clases 0 y 1 en Y_salida\n",
    "indices_clase_0 = [i for i, valor in enumerate(Y_salida) if valor == 0]\n",
    "\n",
    "indices_clase_1 = [i for i, valor in enumerate(Y_salida) if valor == 1]\n",
    "\n",
    "# 2. Obtén la cantidad de instancias de la clase 1 (clase minoritaria)\n",
    "cantidad_clase_1 = len(indices_clase_1)\n",
    "\n",
    "# 3. Selecciona aleatoriamente la misma cantidad de instancias de la clase 0\n",
    "indices_clase_0_submuestreado = np.random.choice(indices_clase_0, size=cantidad_clase_1, replace=False)\n",
    "\n",
    "# 4. Combina las posiciones de las clases 0 submuestreadas y 1\n",
    "indices_combinados = np.concatenate([indices_clase_0_submuestreado, indices_clase_1])\n",
    "\n",
    "\n",
    "# 5. Reordena las posiciones de manera aleatoria\n",
    "np.random.shuffle(indices_combinados)\n",
    "X_entrada = np.array(X_entrada)\n",
    "Y_salida = np.array(Y_salida)\n",
    "\n",
    "# 6. Subconjuntos balanceados de X_entrada y Y_salida\n",
    "X_entrada_balanceado = X_entrada[indices_combinados]\n",
    "Y_salida_balanceado = Y_salida[indices_combinados]\n",
    "\n",
    "# Ahora X_entrada_balanceado y Y_salida_balanceado tienen igual número de instancias para ambas clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_entrada_balanceado, Y_salida_balanceado, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 80.68%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.75      0.79      1390\n",
      "           1       0.79      0.86      0.82      1482\n",
      "\n",
      "    accuracy                           0.81      2872\n",
      "   macro avg       0.81      0.81      0.81      2872\n",
      "weighted avg       0.81      0.81      0.81      2872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Crear y entrenar el modelo XGBoost\n",
    "xgb_model = XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Precisión: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Mostrar un reporte de clasificación\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapeo_etiquetas = {0: 0, 1: 1, 2: 2, 3: 3 ,5 :4, 4:4, 6: 0, 7:0}\n",
    "\n",
    "ruta_salida_deseada = os.path.join(path_agus,'sub-307','ses-day1','sleep_staging','sub-307' + '_ses-day1_task-sleep_sleepStages.mat')\n",
    "y_real__ = scipy.io.loadmat(ruta_salida_deseada)['stageData'][0][0][6][1:] # salida deseada, la del experto\n",
    "y_real = np.array([mapeo_etiquetas[etiqueta] for etiqueta in y_real__.flatten()]).reshape(y_real__.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_uba = pd.read_csv(r'C:\\Users\\Bruno\\OneDrive\\Escritorio\\Proyecto\\AgusGSSC_YASA\\salida_gssc_sub-307.tsv', sep = '\\t')\n",
    "datagssc =pd.read_csv(r'C:\\Users\\Bruno\\OneDrive\\Escritorio\\Proyecto\\AgusGSSC_YASA\\salida_gssc_sub-307.tsv', sep = '\\t')\n",
    "salida_uba = data_uba.iloc[:,5].values\n",
    "\n",
    "\n",
    "y_value = [ 1 if real != prediccion else 0 for real, prediccion in zip(y_real, salida_uba)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "salida_predic = xgb_model.predict(data_uba.iloc[:,0:5].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.728421052631579"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_value,salida_predic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
